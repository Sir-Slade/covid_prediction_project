{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "likely-feelings",
   "metadata": {},
   "source": [
    "# Construction of a prediction model for Covid19\n",
    "## Part 2 (for part one look at the DataExploration notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "received-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from WebApp.CovidClinicalData import DataImputer\n",
    "\n",
    "\n",
    "from colorama import Fore #To pain the terminal with different colors\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #To disable warnings\n",
    "from IPython.display import display #To print a dataframe like the cell does"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-technical",
   "metadata": {},
   "source": [
    "We read the data file created in the Part 1 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "effective-portsmouth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>covid19_test_results</th>\n",
       "      <th>age</th>\n",
       "      <th>high_risk_exposure_occupation</th>\n",
       "      <th>high_risk_interactions</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>chd</th>\n",
       "      <th>htn</th>\n",
       "      <th>cancer</th>\n",
       "      <th>asthma</th>\n",
       "      <th>autoimmune_dis</th>\n",
       "      <th>...</th>\n",
       "      <th>sob</th>\n",
       "      <th>sob_severity</th>\n",
       "      <th>diarrhea</th>\n",
       "      <th>fatigue</th>\n",
       "      <th>headache</th>\n",
       "      <th>loss_of_smell</th>\n",
       "      <th>loss_of_taste</th>\n",
       "      <th>runny_nose</th>\n",
       "      <th>muscle_sore</th>\n",
       "      <th>sore_throat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93989</th>\n",
       "      <td>Negative</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93990</th>\n",
       "      <td>Negative</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93991</th>\n",
       "      <td>Negative</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93993</th>\n",
       "      <td>Negative</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93994</th>\n",
       "      <td>Negative</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51695 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      covid19_test_results  age high_risk_exposure_occupation  \\\n",
       "0                 Negative    4                          True   \n",
       "1                 Negative    2                         False   \n",
       "2                 Negative    1                           NaN   \n",
       "3                 Negative    3                          True   \n",
       "4                 Negative    1                         False   \n",
       "...                    ...  ...                           ...   \n",
       "93989             Negative    3                         False   \n",
       "93990             Negative    3                         False   \n",
       "93991             Negative    3                         False   \n",
       "93993             Negative    3                         False   \n",
       "93994             Negative    2                         False   \n",
       "\n",
       "      high_risk_interactions  diabetes    chd    htn  cancer  asthma  \\\n",
       "0                        NaN     False  False  False   False   False   \n",
       "1                        NaN     False  False  False   False   False   \n",
       "2                        NaN     False  False  False   False   False   \n",
       "3                       True     False  False  False   False   False   \n",
       "4                        NaN     False  False  False   False   False   \n",
       "...                      ...       ...    ...    ...     ...     ...   \n",
       "93989                   True     False  False  False   False   False   \n",
       "93990                   True     False  False  False   False   False   \n",
       "93991                  False     False  False  False   False   False   \n",
       "93993                  False     False  False  False   False   False   \n",
       "93994                  False     False  False  False   False   False   \n",
       "\n",
       "       autoimmune_dis  ...    sob  sob_severity  diarrhea  fatigue  headache  \\\n",
       "0               False  ...  False           0.0     False    False     False   \n",
       "1               False  ...  False           0.0     False    False     False   \n",
       "2               False  ...    NaN           NaN       NaN      NaN       NaN   \n",
       "3               False  ...   True           2.0     False     True     False   \n",
       "4               False  ...  False           0.0     False    False     False   \n",
       "...               ...  ...    ...           ...       ...      ...       ...   \n",
       "93989           False  ...  False           0.0     False    False     False   \n",
       "93990           False  ...  False           0.0     False    False     False   \n",
       "93991           False  ...  False           0.0     False    False     False   \n",
       "93993           False  ...  False           0.0     False    False     False   \n",
       "93994           False  ...  False           0.0     False    False     False   \n",
       "\n",
       "       loss_of_smell  loss_of_taste runny_nose muscle_sore sore_throat  \n",
       "0              False          False      False       False       False  \n",
       "1              False          False      False       False       False  \n",
       "2                NaN            NaN        NaN         NaN         NaN  \n",
       "3              False          False      False       False        True  \n",
       "4              False          False      False       False       False  \n",
       "...              ...            ...        ...         ...         ...  \n",
       "93989          False          False      False       False       False  \n",
       "93990          False          False       True       False        True  \n",
       "93991          False          False      False       False       False  \n",
       "93993          False          False      False       False       False  \n",
       "93994          False          False      False       False       False  \n",
       "\n",
       "[51695 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv(\"covid_clinical_data.csv\", index_col=0)\n",
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-highland",
   "metadata": {},
   "source": [
    "We are going to split the data into a training set on which we will do the parameter tuning and a test set on which we will evaluate the models' performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "silent-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data.iloc[:, 1:]\n",
    "y = all_data[\"covid19_test_results\"]\n",
    "X, test_x, y, test_y = train_test_split(X, y, test_size=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-planet",
   "metadata": {},
   "source": [
    "## Splitting the data\n",
    "\n",
    "Given that the data appears in the dictionary as taken by blocks (and seen how that matches the proportion of null values for every group) I have decided to split the data into the 4 types:<br>\n",
    "- <u>Epidemiological factors:</u> 'age', 'high_risk_exposure_occupation' and 'high_risk_interactions'. These will be included in all datasets since I believe it might affect the results greatly and could be easily ignored for experimentation purposes. \n",
    "- <u>Comorbidities:</u> All columns from 'diabetes' to 'smoker'. Since this is the most complete dataset (almost all instances in the original dataset are not null) we will start with this.\n",
    "- <u>Vitals:</u> All of the continues values ('temperature', 'pulse', etc.) I try to use simple linear regression and compare it against both trees and xgboost algorithms.\n",
    "- <u>Clinician Assessed symptoms:</u> 'ctab', 'labored_respiration', 'rhonchi' and 'wheezes'. I will use naive bayes, trees and/or xgboost.\n",
    "- <u>Patient reported symptoms:</u> All remaining columns. Again, naive bayes, trees and/or xgboost.\n",
    "\n",
    "After I have each dataset, I will impute the null corresponding to the most frequent in each case and train several models for each one of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "regulation-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_different_datasets(data_x):\n",
    "    e_factors = data_x.iloc[:,:3]\n",
    "    comorbidities_data = data_x.iloc[:, 3:10] #The columns that contain the comorbidities\n",
    "    vitals_data = data_x.iloc[:, 10:16] #The columns that contain the vitals\n",
    "    assesed_symptoms_data = data_x.iloc[:, 16:21] #The columns that contain the assesed symptoms\n",
    "    reported_symptoms_data = data_x.iloc[:,21:] #The columns that have the patient reported symptoms\n",
    "    \n",
    "    return e_factors, comorbidities_data, vitals_data, assesed_symptoms_data, reported_symptoms_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "refined-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_factors, comorb, vitals, a_symptoms, r_symptoms = create_different_datasets(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-heather",
   "metadata": {},
   "source": [
    "<u>high_risk_exposure_occupation:</u> The most obvious thing to do is to just fill the 169 missing values with the most frequent value. However, it occurred to me that since we ultimately are willing to have (maybe even encourage) false positives, it might be better to just put the ones that tested positive as True and the rest as False. This would require that I split the dataset into training, validation and testing set before I do any imputation to avoid any target leakage (the effect when knowing the result before hand affects how are we imputing the variables). The step to be taken (if I were to follow that route) would be then to impute the training data that tested positive as True, the rest as False, and any incoming unknown data (validation and test data) as True if we dont know the value of the feature. I might need to run an experiment when I do both.\n",
    "\n",
    "<u>high_risk_interaction:</u> This is easier than the previous one. We will just assign True to anything that has a 'high_risk_expossure_occupation' as True. The reasoning behind is is that if we don't know if the patient has had a high risk interaction, makes sense to say they did if their occupation is of high risk exposure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "prompt-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_training_set(data_x, data_y, ratio=1):\n",
    "    '''\n",
    "    Undersamples the 'Negative' classes so we end up with nPositives * ratio 'Negative' examples\n",
    "    '''\n",
    "    selected_negatives = data_x[data_y[data_x.index] == \"Negative\"].sample((data_y[data_x.index] == \"Positive\").sum() * ratio)\n",
    "    all_positives = data_x[data_y == \"Positive\"]\n",
    "    #reduced_train_comorb = pd.merge(all_positives, selected_negatives) #Doesn't work well for reasons...\n",
    "    reduced_data = pd.concat([all_positives, selected_negatives])\n",
    "\n",
    "    return reduced_data\n",
    "\n",
    "def specificity_score(*values):    \n",
    "    cm = confusion_matrix(*values)    \n",
    "    return cm[0][0] / (cm[0][0] + cm[0][1]) \n",
    "\n",
    "\n",
    "def get_metrics(*values):\n",
    "    '''\n",
    "        Gets evaluation metrics for a set of predictions\n",
    "        values: a tuple in the form of '(actual, predictions)'\n",
    "    '''\n",
    "    accuracy = accuracy_score(*values)\n",
    "    recall = recall_score(*values, pos_label=\"Positive\")\n",
    "    precision = precision_score(*values, pos_label=\"Positive\")\n",
    "    f1 = f1_score(*values, pos_label=\"Positive\")\n",
    "    specificity = specificity_score(*values)\n",
    "    return recall, f1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "automotive-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBAdapter:\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        self.model = XGBClassifier(**params, verbosity=0)\n",
    "        \n",
    "    def fit(self, data_x, data_y, sample_weight=None):\n",
    "        self.model.fit(self.xgb_adapter(data_x), data_y, sample_weight=sample_weight)\n",
    "        \n",
    "    def predict(self, data_x):\n",
    "        return self.model.predict(self.xgb_adapter(data_x))\n",
    "    \n",
    "    def predict_proba(self, data_x):\n",
    "        return self.model.predict_proba(self.xgb_adapter(data_x))\n",
    "    \n",
    "    def score(self, X, y, sample_weight=None):\n",
    "        return self.model.score(X, y, sample_weight=None)\n",
    "    \n",
    "    #This function is because xgb complains about 'object' type columns so I convert them all to boolean\n",
    "    def xgb_adapter(self, data_x):\n",
    "        result = data_x.copy()\n",
    "        for column in result:\n",
    "            if data_x[column].dtype == \"object\":\n",
    "                result.loc[:,column] = result[column].astype(\"bool\")\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "powerful-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_normal(data_x, data_y, model, folds, sample_weights=None, class_threshold=.5):\n",
    "    results = np.zeros((folds,2,6)) #Shape of folds, training and validation, and number of metrics\n",
    "    if sample_weights is None:\n",
    "        sample_weights = np.ones(data_y.shape)\n",
    "       \n",
    "    data_x = data_x.sample(data_x.shape[0])\n",
    "    fold_size = data_x.shape[0] // folds\n",
    "    reminder = data_x.shape[0] % folds    \n",
    "    start = 0    \n",
    "    imputer = Imputer()\n",
    "    for i in range(folds):\n",
    "        end = start + fold_size + (1 if reminder > 0 else 0)\n",
    "        reminder-=1\n",
    "        train_x = pd.concat([data_x.iloc[:start], data_x.iloc[end:]], axis=0)\n",
    "        train_y = data_y[train_x.index]\n",
    "        valid_x = data_x.iloc[start:end]\n",
    "        valid_y = data_y[valid_x.index]\n",
    "                    \n",
    "        imputer.fit_transform(train_x, train_y)\n",
    "        imputer.transform(valid_x)\n",
    "            \n",
    "        model.fit(train_x, train_y, sample_weight=np.append(sample_weights[:start], sample_weights[end:]))\n",
    "        ##The following lines are for predicting via probability\n",
    "        t_pred_prob = model.predict_proba(train_x)[:,1] ## We choose '1' in predict_proba since that is the positive class\n",
    "        v_pred_prob = model.predict_proba(valid_x)[:,1]  ## We choose '1' in predict_proba since that is the positive class      \n",
    "        \n",
    "        t_preds = np.zeros(train_x.shape[0], dtype = np.object)\n",
    "        t_preds[t_pred_prob > class_threshold] = \"Positive\"\n",
    "        t_preds[t_pred_prob <= class_threshold] = \"Negative\"\n",
    "        \n",
    "        v_preds = np.zeros(valid_x.shape[0], dtype = np.object)\n",
    "        v_preds[v_pred_prob > class_threshold] = \"Positive\"\n",
    "        v_preds[v_pred_prob <= class_threshold] = \"Negative\"\n",
    "        \n",
    "        ##End of probability calculations\n",
    "        \n",
    "        train_v = (train_y, t_preds) #original: insted of t_preds is model.predict\n",
    "        valid_v = (valid_y, v_preds)  #original: insted of v_preds is model.predict\n",
    "        results[i,0] += get_metrics(*train_v) + (roc_auc_score(train_y, t_pred_prob),) ## We add a comma to turn the result into a tuple so we can append it\n",
    "        results[i,1] += get_metrics(*valid_v) + (roc_auc_score(valid_y, v_pred_prob),) ## We add a comma to turn the result into a tuple so we can append it\n",
    "        start = end\n",
    "        \n",
    "        progress_bar = \"╠\" + str(\"■\" * i) + str(\" \" * (folds -(i+1))) + \"╣\"\n",
    "        print(progress_bar, end=\"\\r\")\n",
    "    print(\"\")    \n",
    "       \n",
    "    \n",
    "    return results.mean(axis=0), results.std(ddof=1, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "def cross_validation_class_ratios(data_x, data_y, model, folds, ratio_negatives_to_positives=1, class_threshold=.5, sample_weights=None):\n",
    "    \n",
    "    positive_index = data_y[data_y == \"Positive\"].index\n",
    "    size_of_negatives = min(positive_index.shape[0] * ratio_negatives_to_positives, data_y[data_y == \"Negative\"].index.shape[0])\n",
    "    \n",
    "    fold_size = positive_index.shape[0] // folds\n",
    "    fold_size_neg = fold_size * ratio_negatives_to_positives\n",
    "    \n",
    "    results = np.zeros((folds,2,3)) #Shape of folds, training and validation, and number of metrics   \n",
    "        \n",
    "    reminder = positive_index.shape[0] % folds\n",
    "    \n",
    "    imputer = DataImputer()\n",
    "    start = 0    \n",
    "    for i in range(folds):\n",
    "        end = start + fold_size + (1 if reminder > 0 else 0)\n",
    "        reminder-=1        \n",
    "        training_positives = np.setdiff1d(positive_index, positive_index[start:end]) #The index of positives to be used as training set\n",
    "                \n",
    "        # Sample the size of negatives- the size of the fold negatives for training and concatenate with the corresponding indexes for the fold\n",
    "        train_x = pd.concat([data_x[data_y == \"Negative\"].sample(size_of_negatives - fold_size_neg), data_x.loc[training_positives]], axis=0) # 'loc' instead of 'iloc' because the indexes are treated as labels, not numbers\n",
    "        train_y = data_y[train_x.index]\n",
    "        \n",
    "        rest_of_x = data_x.loc[~data_x.index.isin(train_x.index)] ## Al data not used by training\n",
    "        valid_x = pd.concat([rest_of_x[data_y == \"Negative\"].sample(fold_size_neg), data_x.loc[positive_index[start:end]]], axis=0) # 'loc' instead of 'iloc' because the indexes are treated as labels, not numbers\n",
    "        valid_y = data_y[valid_x.index]\n",
    "        \n",
    "        imputer.fit_transform(train_x, train_y)\n",
    "        imputer.transform(valid_x)\n",
    "                    \n",
    "        model.fit(train_x, train_y)\n",
    "        \n",
    "        ##The following lines are for predicting via probability\n",
    "        t_pred_prob = model.predict_proba(train_x)[:,1] ## We choose '1' in predict_proba since that is the positive class\n",
    "        v_pred_prob = model.predict_proba(valid_x)[:,1]  ## We choose '1' in predict_proba since that is the positive class      \n",
    "               \n",
    "        t_preds = np.zeros(train_x.shape[0], dtype = np.object)\n",
    "        t_preds[t_pred_prob > class_threshold] = \"Positive\"\n",
    "        t_preds[t_pred_prob <= class_threshold] = \"Negative\"\n",
    "        \n",
    "        v_preds = np.zeros(valid_x.shape[0], dtype = np.object)\n",
    "        v_preds[v_pred_prob > class_threshold] = \"Positive\"\n",
    "        v_preds[v_pred_prob <= class_threshold] = \"Negative\"\n",
    "        \n",
    "        ##End of probability calculations\n",
    "        \n",
    "        train_v = (train_y, t_preds) #original: insted of t_preds is model.predict\n",
    "        valid_v = (valid_y, v_preds)  #original: insted of v_preds is model.predict\n",
    "        results[i,0] += get_metrics(*train_v) + (roc_auc_score(train_y, t_pred_prob),) ## We add a comma to turn the result into a tuple so we can append it\n",
    "        results[i,1] += get_metrics(*valid_v) + (roc_auc_score(valid_y, v_pred_prob),) ## We add a comma to turn the result into a tuple so we can append it\n",
    "        start = end\n",
    "        \n",
    "        progress_bar = \"╠\" + str(\"■\" * i) + str(\" \" * (folds -(i+1))) + \"╣\"\n",
    "        print(progress_bar, end=\"\\r\")\n",
    "                    \n",
    "    print(\"\")\n",
    "    \n",
    "    return results.mean(axis=0), results.std(ddof=1, axis=0) # 'ddof=1' means the divisor will be n-1 (ddof is degrees of freedom) since this is a sample of all possible results\n",
    "\n",
    "def run_threshold(data_x, data_y, model, thresholds=np.linspace(0,1, num=11), folds=10, ratio_negatives_to_positives=1):\n",
    "    \n",
    "    threshold_scores = np.zeros((5,thresholds.shape[0]))\n",
    "    i = 0 #the threshold index im in\n",
    "    for t in thresholds:      \n",
    "        print(\"Threshold:\", t)\n",
    "        results_mean, results_std = cross_validation_class_ratios(data_x, data_y, model, folds, ratio_negatives_to_positives=ratio_negatives_to_positives, class_threshold=t, plot_roc=False, feature_importances=False)\n",
    "         \n",
    "        for metric in range(5):\n",
    "            threshold_scores[metric,i] = results_mean[1][metric]      \n",
    "        i+=1\n",
    "    \n",
    "    plt.figure(figsize=(21,7))\n",
    "    plt.plot(thresholds, threshold_scores[1], label=\"Recall\")\n",
    "    plt.plot(thresholds, threshold_scores[4], label=\"F1 score\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    display(pd.DataFrame(threshold_scores, index=[\"Accuracy\", \"Recall\", \"Precision\", \"Specificity\", \"F1\"], columns=thresholds))\n",
    "        \n",
    "def run_models(data_x, data_y, models, folds=10, ratio_negatives_to_positives=-1, sample_weights=None):\n",
    "    result_table = np.zeros((2,len(models), 3))\n",
    "    i = 0\n",
    "    for model in models:\n",
    "        print(Fore.RED, model, Fore.BLACK, sep=\"\")\n",
    "        try:\n",
    "            if(ratio_negatives_to_positives >= 1):            \n",
    "                results_mean, results_std = cross_validation_class_ratios(data_x, data_y, models[model], folds, ratio_negatives_to_positives)\n",
    "            else:\n",
    "                results_mean, results_std = cross_validation_normal(data_x, data_y, models[model], folds, sample_weights)    \n",
    "            \n",
    "            result_table[0,i] = results_mean[1]\n",
    "            result_table[1,i] = results_std[1]\n",
    "            \n",
    "            print(\"\")\n",
    "            print(\"Mean metrics\")\n",
    "            display(pd.DataFrame(results_mean, index=[\"Training\", \"Validation\"], columns=[\"Recall\",\"F1\", \"ROC_AUC\"]))\n",
    "            print(\"Spread in metrics (sample std)\")\n",
    "            display(pd.DataFrame(results_std, index=[\"Training\", \"Validation\"], columns=[\"Recall\",\"F1\", \"ROC_AUC\"]))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        i+=1\n",
    "        \n",
    "    pd.options.display.float_format = '{:.8f}'.format\n",
    "    display(pd.DataFrame(result_table[0], index=models.keys(), columns=[\"Recall\", \"F1\", \"ROC_AUC\"]))\n",
    "    \n",
    "    pd.options.display.float_format = '{:.3f}'.format\n",
    "    # The 2 in here is an aproximation of the t/z critical value (1.96 for z, and 2.2 for 9 degrees of freedom, so 2 is a good indication for certainty above 90%, reaching towards 95%)\n",
    "    lower_bound_df = pd.DataFrame((result_table[0]- 2*(result_table[1] / np.sqrt(folds))).astype(\"str\"), index=models.keys(), columns=[\"Recall\", \"F1\", \"ROC_AUC\"]) # We use a value of 2 stds for a 95% confidence level\n",
    "    upper_bound_df = pd.DataFrame((result_table[0]+ 2*(result_table[1] / np.sqrt(folds))).astype(\"str\"), index=models.keys(), columns=[\"Recall\", \"F1\", \"ROC_AUC\"])\n",
    "    interval_df = lower_bound_df + \"-\" + upper_bound_df\n",
    "    \n",
    "    display(interval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "future-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "models ={\n",
    "    \"Dummy Random\" : DummyClassifier(strategy=\"uniform\"), #does not have predict_proba\n",
    "    \"MultinomialNB\" : MultinomialNB(alpha=0, class_prior=(.5, .5)),\n",
    "    \"Random Forest (100 estimators)\" : RandomForestClassifier(min_samples_leaf=100),\n",
    "    \"XGBoost Classifier\" : XGBAdapter(n_estimators=500),\n",
    "    \"SVM\" : SVC(kernel='linear', probability=True), \n",
    "    \"KNN\" : KNeighborsClassifier(n_neighbors=100, weights=\"distance\"), \n",
    "    \"Logistic Regression\" : LogisticRegression()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-elephant",
   "metadata": {},
   "source": [
    "Most of the models don't do better than random guessing (the metric we want to optimize is recall; however, since the data is being undersampled to combat the class imbalance, Accuracy is a good metric to keep an eye on as well). <b>Asthma</b>, <b>Smoker</b> and <b>Diabetes</b> seem to be the most prominent features, although they don't seem to be consistent (they change every time I run the cell again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "miniature-shade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mDummy Random\u001b[30m\n",
      "name 'imp_x' is not defined\n",
      "\u001b[31mMultinomialNB\u001b[30m\n",
      "name 'imp_x' is not defined\n",
      "\u001b[31mRandom Forest (100 estimators)\u001b[30m\n",
      "name 'imp_x' is not defined\n",
      "\u001b[31mXGBoost Classifier\u001b[30m\n",
      "name 'imp_x' is not defined\n",
      "\u001b[31mSVM\u001b[30m\n",
      "name 'imp_x' is not defined\n",
      "\u001b[31mKNN\u001b[30m\n",
      "name 'imp_x' is not defined\n",
      "\u001b[31mLogistic Regression\u001b[30m\n",
      "name 'imp_x' is not defined\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy Random</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest (100 estimators)</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost Classifier</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Recall         F1    ROC_AUC\n",
       "Dummy Random                   0.00000000 0.00000000 0.00000000\n",
       "MultinomialNB                  0.00000000 0.00000000 0.00000000\n",
       "Random Forest (100 estimators) 0.00000000 0.00000000 0.00000000\n",
       "XGBoost Classifier             0.00000000 0.00000000 0.00000000\n",
       "SVM                            0.00000000 0.00000000 0.00000000\n",
       "KNN                            0.00000000 0.00000000 0.00000000\n",
       "Logistic Regression            0.00000000 0.00000000 0.00000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy Random</th>\n",
       "      <td>0.0-0.0</td>\n",
       "      <td>0.0-0.0</td>\n",
       "      <td>0.0-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.0-0.0</td>\n",
       "      <td>0.0-0.0</td>\n",
       "      <td>0.0-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest (100 estimators)</th>\n",
       "      <td>0.0-0.0</td>\n",
       "      <td>0.0-0.0</td>\n",
       "      <td>0.0-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost Classifier</th>\n",
       "      <td>0.0-0.0</td>\n",
       "      <td>0.0-0.0</td>\n",
       "      <td>0.0-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.0-0.0</td>\n",
       "      <td>0.0-0.0</td>\n",
       "      <td>0.0-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.0-0.0</td>\n",
       "      <td>0.0-0.0</td>\n",
       "      <td>0.0-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.0-0.0</td>\n",
       "      <td>0.0-0.0</td>\n",
       "      <td>0.0-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Recall       F1  ROC_AUC\n",
       "Dummy Random                    0.0-0.0  0.0-0.0  0.0-0.0\n",
       "MultinomialNB                   0.0-0.0  0.0-0.0  0.0-0.0\n",
       "Random Forest (100 estimators)  0.0-0.0  0.0-0.0  0.0-0.0\n",
       "XGBoost Classifier              0.0-0.0  0.0-0.0  0.0-0.0\n",
       "SVM                             0.0-0.0  0.0-0.0  0.0-0.0\n",
       "KNN                             0.0-0.0  0.0-0.0  0.0-0.0\n",
       "Logistic Regression             0.0-0.0  0.0-0.0  0.0-0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comorb_ef = pd.concat([comorb.drop(columns=\"smoker\"), e_factors.drop(columns=\"age\")], axis=1)\n",
    "run_models(comorb_ef, y[comorb_ef.index], models, ratio_negatives_to_positives = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-delta",
   "metadata": {},
   "source": [
    "We definetley need another set, even though using the cross validation for data imbalancing helped a lot. <b>High risk exposure occupation</b> seems to be the most important feature from epidemiological factors. <i>Note:</i> Most of the models have really high specificity, which might not be a good thing since the recall is really low and both precision and accuracy are just around .5 (this experiments use undersampling to have balanced classes). This suggests that most of the models are predicting everything is negative."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
